\chapter{Conclusions}
\label{chap:conclusions}

\section{Summary}
We experimented if simulating strategies of various cohorts of players would produce agents' \acs{sr} that can be used to better predict the players' \acs{sr} on new generated game content. We proposed two different approaches to model different player strategies by directly learning them from real player data without expert knowledge. We validated our approaches using the \textit{Candy Crush Saga} game as a test bed. We tracked several player metrics and gameplay data consisting of the game board and the performed move for levels in the range [1, 2945]. In the first approach, called clustering players, we divided the tracked state-action pairs based on the performances of the players that have been tracked. Then, we trained different \acs{CNN}-based agents on each generated player cluster. On the contrary, the second approach, called clustering simulated strategies, is based on the idea of letting the network discover the relationship between player features and player strategy. We trained a \acs{CNN}-based agent that received as input three different player features in addition to the game board. Then, during prediction, by changing the input features we were able to predict different moves and as a consequence to simulate different players. We tested both of the proposed approaches against the state-of-the-art method that simulates an average strategy learnt from a random sample of real players. The goal was to understand if simulating different player strategies could generate agents' \acs{sr} that can be used to better predict players' \acs{sr} on new levels. All the simulations where performed by running 100 attempts for each level and aggregating the results to compute the agent's \acs{sr}. Then, we used linear regression models to map from the agents' \acs{sr} to the players' \acs{sr}. In the clustering players approach we fitted a different linear model for each agent and we combined the predictions based on the percentage of players that each agent simulates. In the clustering simulated strategies approach we used a single linear model that directly combines the various agents' \acs{sr}. Then, we used the developed linear models to predict players' \acs{sr} on test levels. This corresponds to how the approaches could be used in practice. The training will be done on all the available levels and the models will be used to predict on newly created levels. Finally, we compared the prediction performances of our approaches with the state-of-the-art approach. 
We found that both the approaches were able to improve the \acs{MAE} by 13\% and the \acs{MSE} by approximately 23\% in the linear regression part. Adding the mean predictions to have an estimate of the players' \acs{sr} also for levels where the agents failed reduced the improvements. However, also in this case, the proposed approaches performed better then the baseline approach. 
Furthermore, we found that not all the developed agents were strictly necessary to predict the players' \acs{sr} and reducing the number of agent maintained the same prediction accuracy while saving computational resources. We discussed how the clustering players approach favors interpretability and it can provide game designers with multiple difficulty measures, perceived by different type of players instead of only the average perceived difficulty. On the contrary, we discussed how the clustering simulated strategy approach can work without any assumption on the relationship between player features and strategies and how it allows to use all the available data during training. Finally, we discussed limitations and future work that could possibly improve the developed approaches.

\section{Conclusions}
To conclude, we have been able to model different player strategies while directly learning them from real player data. Incorporating characteristics of the players into the model allowed us to improve the prediction accuracy of the \acs{CNN}-based agents as well as the players' \acs{sr} prediction of the linear models. Furthermore, using the proposed approaches, we have been able to provide game designers with level difficulty measures perceived by different cohorts of players helping them to iteratively balance game content and create the best possible player experience.

To answer our research question, results suggested that player modeling can improve the level difficulty estimation of a \acs{CNN}-based agent simulating human gameplay. As a consequence, player modeling techniques can be used to improve automatic playtesting. In addition, the proposed approaches are general and can be extended to work with other games and different player features or to estimate different metrics. 